---
title: "EmployeePromotion"
output:
  pdf_document: default
  html_document: default
date: "2023-02-18"
---

Poner aquí documentación

Este proyecto está realizado por el grupo 3 formado por José Arturo Espaillat, Johnsiel Castaños, José Delgado, Salama Mohamed-fadel Sidna. El dataset elegido es llamado HR Analytics: Employer Promotion Data (https://www.kaggle.com/datasets/arashnic/hr-ana?select=test.csv) sacado de Kaggle, el cual cuenta con X columnas y X filas para analizar si un empleado será o no promocionado. Hablar más de esto, mirar Rúbica

Para organizarnos, hemos decidido crear un repositorio en GitHub (https://github.com/Josdelser/DataScienceEmployeePromotion/tree/develop) para trabajar simultáneamente. También hemos creado una bolsa de preguntas y las hemos asignado según las capacidades y aspiraciones de cada persona. En el caso de que algún miembro quiera obtener una calificación más alta, deberá realizar un mayor número de preguntas individuales. Todos los miembros realizarán una pregunta para la parte grupal y se ha intentado que estas preguntas estén relacionadas con las preguntas individuales, para poder afrontar mejor el reto. A continuación, se detalla la bolsa de preguntas y la asignación de cada miembro.


Jose Delgado:

  -Grupal
  
    ¿Podemos sacar conclusiones tempranas de que variables afectan prediciendo si será promovido un empleado?
    
    ¿Quitando variables mejorará el arbol?
    
    
  -Individual:
    
    ¿Nos puede ayudar la visualización a sacar conclusiones temprana?
    
    Uso de la correlacion cramer para responder a ¿Existe una correlación significativa entre la variable categórica "education" y la variable objetivo "is_promoted"?
 

    

    
    
Salama:
Johnsiel:
Jose Espaillat:
    
    
Cada miembro realizará la documentación de ambas partes asignadas. Además en el documento se indicará donde empieza y acaba la parte de cada miembro para que así sea mas sencilla su evaluación. 

```{r}
library(dplyr)
library(rpart)
library(rpart.plot)
library(rattle)
library(dplyr)
library(ggplot2)
library(RColorBrewer)
library(ggfortify)
library(vcd)


require(corrplot)


set.seed(28)
```


Información general del Dataset

```{r}
data<- read.csv("train.csv")
data <- rename(data, awards_won = awards_won.)
head(data)
colnames(data)
attach(data)
```

```{r}
str(data)
dim(data)
object.size(data)/1024
```

```{r}
print(paste("Número de valores faltantes totales:", sum(is.na(data))))
data <- na.omit(data)
data <- unique(data)

```
*Aquí empieza la parte de Jose Delgado

Una vez cargado el dataset y tratado minimamente vamos a pasar a hacer responder a las preguntas, primero la pregunta grupal:

¿Como predecir si será promovido un empleado?

La cual se plantea responder mediante una predicción utilizando validacion cruzada (cross_validation), para ello podemos tirar de regresión lógistica o un árbol de decisión. En este caso usaré arboles de decisión para así también ver que variables inlfuyen y poder comparar este resultado con las preguntas individuales 


Primero le hacemos preprocesamiento de manera preparatoria a la prediccion, luego dividimos el dataset en conjunto de prueba(test) y entrenamiento(train) para obtener resultado
```{r}
datajose <- data
```

```{r}
dep_levels <- unique(datajose$department)
gen_levels <- unique(datajose$gender)
recru_levels <- unique(datajose$recruitment_channel)
promo_levels <- unique(datajose$is_promoted )
award_levels <- unique(datajose$awards_won)


datajose$department <- factor(datajose$department, levels = dep_levels)
datajose$gender  <- factor(datajose$gender , levels = gen_levels)
datajose$recruitment_channel <- factor(datajose$recruitment_channel, levels = recru_levels)
datajose$is_promoted <- factor(datajose$is_promoted, levels = promo_levels)
datajose$awards_won <- factor(datajose$awards_won, levels = award_levels)

```

```{r}
datajosepred <-datajose
```



```{r}
division <- createDataPartition(datajosepred$is_promoted, p = .7, list = FALSE, times = 1)
train <- datajosepred[division, ]
test  <- datajosepred[-division, ]
```

Entrenamos el modelo y visualizamos para tener una primera imagen de las variables decisivas 

```{r}
arbol <- rpart(formula =  is_promoted  ~ ., data = train, method = 'class')

fancyRpartPlot(arbol)
```



Podemos observar que la variable que mas afecta es la puntuación en el rango superior a 91, donde con un 99% de posibilidades seras promocionado. AL tener una variable con tanta importancia se nos viene a la cabeza otra pregunta: Quitando esta variable, ¿Como sería el arbol final?. Se plantea segunda pregunta

Pasamos a predecir según clasifacación 

```{r}
prediccion <-predict(arbol, test, type = "class")
```
 
Ahora toca evaluar el rendimiento según validación cruzada. 

```{r}
valcruz <- trainControl(method = "cv", number = 10)

arbolfit <- train(is_promoted ~ ., data = train, method = "rpart",
                 trControl = valcruz, tuneLength = 10)
```

Graficamos

```{r}
rpart.plot(arbolfit$finalModel, type = 2, extra = 1)

```

Mejoras visualizacion
```{r}
prp(arbolfit$finalModel, type = 2, nn = TRUE, 
    fallen.leaves = FALSE,
    varlen = 0,  shadow.col = "gray")
```
```{r}
prediccionTest <- predict(arbolfit, newdata = test)
confusionMatrix(prediccionTest, test$is_promoted)
```
Con estos datos ya podemos sacar conclusiones sobre el modelo:
  
  - Hay 13,861 verdaderos negativos y 254 verdaderos positivos
  
  - Hay 1,044 falsos negativos y 45 falsos positivos

Ya con estos valores vemos que el modelo esta bien ajustado. Con estos datos obtenemos una precisión del 92,8% y una tasa de error del 7,16%. También observamos que tenemos mayor capacidad para acerta, es decir predecir cuando se va a promover que cuando no se va a promover.

Ademas observando el arbolfit vemos que ya aparecen mas variables que son relevantes como award_won y previus_year_rating. Añadir que vemos una fuerte tendencia en el departamento de analiticas, donde superando los 82 puntos serás promocionado con alta seguridad. 

Segunda pregunta

    ¿Quitando variables mejorará el arbol?



Hemos visto que avg_training_score tiene mucho peso, por lo que me surgió la pregunta de que si eliminando esta variable que otras variables afectan, ademas de ver si mejoramos el modelo.

```{r}
datajosearbol2 <-datajose
```

```{r}
arbol2 <- rpart(is_promoted ~ . - avg_training_score, data = datajosearbol2, method = "class")
fancyRpartPlot(arbol2)

```
Directamente vemos que nos da resultados parecidos al arbol entrenado, volviendo a afirmar que el modelo está bien ajustado. Con esta conclusion nos ahorramos de volver a predecir ya que intuimos que en el mejor de los casos va a igualar a los resultados anteriores. Gracias a un analisis previo nos hemos ahorrado esta parte. 


Jose preguntas individuales:


Una vez hecha la predicion, me pregunté si hay alguna gráfica que me hubiese podido ayudar a sacar una conclusion temprana de las variables que mas afectan. Para ello voy a realizar graficas tanto para variables numericas como categoricas.

Pondré el caso de que no hemos predecido todavia y no se que variables afectan, de esta manera simularé un problema real ya que tenderé a ir a por las variables que creo que pueden afectar más

```{r}
datajosegraficas <- datajose
```

Primero vamos a ver las variables categoricas. Empezamos por ver si los estudios influye, vamos a graficar la distribuccion de empleados promoviodos segun sus estudios 

```{r}
ggplot(data = datajosegraficas, aes(x = education, fill = is_promoted)) +
  geom_bar(position = "dodge") +
  labs(title = "Promocionado según estudios", 
       x = "Nivel de estudios", 
       y = "Total",
       fill = "Promovido") +
  theme_bw()

```
Observamos que la mayoría tienen como minimo el bachillerato y luego el Master. Podemos pensar que es una variable que afecta debido a las diferencias entre promovido o no pero no es decisiva o tiene una importancia mayor.

Repetimos pero con los premios ganados
¡
```{r}
ggplot(data = datajosegraficas, aes(x = awards_won, fill = is_promoted)) +
  geom_bar(position = "stack") +
  labs(title = "Promovido por premios ganados", 
       x = "Premio", 
       y = "Total",
       fill = "Promovido") +
  theme_bw()

```
Se observa que en los que están promovimos tiene mayor relevancia tener un premio, ya que el numero de promovidos con premios es notablemente mayor aunque a simple vista no se observe.

```{r}
ggplot(data = datajosegraficas, aes(x = department, fill = is_promoted)) +
  geom_bar(position = "stack") +
  labs(title = "Promocionado según departamento", 
       x = "Departamento", 
       y = "Total",
       fill = "Promovido") +
  theme_bw()

```
Con este grafico de barras apiladas vemos que esta variable no afecta fuertemente a la promocion ya que cada departamente tiene resultados iguales si no contamos en proporcion porque al no saber a que se dedica la empresa no podemos justificar el numero de empleados por cada departamento.


Por último vamos a ver si el genero afecta
```{r}
ggplot(data = datajosegraficas, aes(x = gender, fill = is_promoted)) +
  geom_bar(position = "stack") +
  labs(title = "Promovido por géneros", 
       x = "Géneros", 
       y = "Total",
       fill = "Promovido") +
  theme_bw()

```
Aqui vemos que en proporcion que no afecta el género, ya que a simple vista los porcentajes de promocio segun el sexo parecen cercanoss.



Ahora pasamos a las variables numericas.

Empezamos con la edad representada en un grafico de densidad para ver donde se concentran la mayoria de promocionados por si vemos que la edad pueda afectar ya que tambien está relacionada con el tiempo que lleves en la empresa

```{r}
ggplot(data = datajosegraficas, aes(x = age, fill = is_promoted)) +
  geom_density(alpha = 0.5) +
  labs(title = "Promovido según edad", 
       x = "Edad", 
       y = "Densidad",
       fill = "Promovido") +
  theme_bw()

```

El rango es bastante amplio por lo que no vemos que al edad concreta pueda afectar, pero si puede afectar dependiendo de los años que lleve en la empresa, es decir, una person con 40 años tiene mas probabildiad de llevar mas tiempo en la empresa que una persona de 20. Por eso vamos a graficar ahora si el tiempo en la empresa afecta

```{r}
ggplot(data = datajosegraficas, aes(x = is_promoted, fill = factor(previous_year_rating))) +
  geom_bar(position = "stack") +
  labs(x = "Promovido", y = "Número de empleados") +
  ggtitle("Gráfico de barras apiladas para la variable 'previous_year_rating'") 
 

```
Ahora si encontamos dos grupos que afectan a la promocion, los que llevan 5 años y 3.



Por último vamos a probar con la variable avg_training_score para ver si esta nos afecta.Para ello vamos con un gráfico de cajas y bigotes

```{r}
ggplot(data = datajosegraficas, aes(x = is_promoted, y = avg_training_score)) +
  geom_boxplot() +
  labs(x = "Promovido", y = "Puntuación de entrenamiento promedio") +
  ggtitle("Gráfico de cajas y bigotes para la variable 'avg_training_score'")

```


Observamos que la variable av_training_score es bastante importante ya que por encima de cierto rango se concentra todos los que han sido promovidos.


La conclusion final que sacamos de estos gráficas está bastantante relacionada con la de la prediccion. Vemos que ciertas variables tienden a afectar de manera directa a la promocion y tanto en graficas como en prediccion concuerdan unas con otras.


Segunda pregunta individual


    Uso de la correlacion cramer para responder a ¿Existe una correlación significativa entre las variables categórica del dataset y la variable objetivo "is_promoted"?
    
La relación de cramer es un coeficiente que nos indica el grado de relación entre dos variables categoricas, de esta manera si probamos todas la variables categorias frente a is_promoted podremos analizar cuales son las que mayor relación tienen. Obviaremos las variables como region, genero y recuitment_channel ya que previamente hemos visto que no tienen una relacion importante. Se realizará con departamentos, estudios, genero y premios ganados


Para ello primero tenemos que crear tablas de contigencias con las variables

```{r}
tabladepa <- table(datajose$department, datajose$is_promoted)
tablagen <- table(datajose$gender, datajose$is_promoted)
tablaedu <- table(datajose$education, datajose$is_promoted)
tablawards <- table(datajose$awards_won, datajose$is_promoted)
```


```{r}
cramerdepa<-assocstats(tabladepa)
cramergen<-assocstats(tablagen)
crameredu<-assocstats(tablaedu)
cramerawards<-assocstats(tablawards)
```

```{r}
cramerdepa$cramer
cramergen$cramer
crameredu$cramer
cramerawards$cramer
```
Esto resultados son la V de cramer que nos da la relacion. Observamos, como tambien hemos demostrado arriba con las graficas, que tener un premio ganado tiena cierta importancia y sobre todo respecto al departamento  y educacion. Volver a corroborar que el genero no influyen en nada a la hora de ser promovido  





* Aquí empieza la parte de Salama




<strong>Lectura del dataset train.csv</strong>
```{r,eval=TRUE,echo=TRUE}
data_Salama <- read.csv ("train.csv")
head(data_Salama,5)
```

<strong>Descripcion de dataset data_Salama</strong>

```{r,eval=TRUE,echo=TRUE}
str(data_Salama)

n_col <- ncol(data_Salama)
n_row <- nrow(data_Salama)

cat("Nombre de variables : ", n_col, ", y el nombre de instancias: ", n_row) 
```


<strong>Variables con valores NA</strong>
```{r,eval=TRUE,echo=TRUE}
cat("Los variables que contienen valore NA son: \n")
colnames(data_Salama)[colSums(is.na(data_Salama)) > 0]


cat("\n\n Nombre de NA en cada columna:  \n")
colSums(is.na(data_Salama))
```



******
# Crear variables
******


<strong>la edad a la que el empleado entró en la compañia</strong>
```{r,eval=TRUE,echo=TRUE}
data_Salama <- data_Salama %>%
mutate(data_Salama, employee_start_age = as.numeric(data_Salama$age - data_Salama$length_of_service))
head(data_Salama,5)
```



<strong>Recodificación de la variable "AGE" en cuatro grupos</strong>
```{r,eval=TRUE,echo=TRUE}

min_age = min(data_Salama$age)
max_age = max(data_Salama$age)
lg_age = as.numeric(as.integer( (  max_age - min_age)/4) )

data_Salama <- data_Salama %>%
mutate(data_Salama, age_group = ifelse(data_Salama$age >= min_age & data_Salama$age < (min_age + lg_age), "twenties",
 ifelse(data_Salama$age >= (min_age + lg_age) & data_Salama$age < (min_age + (2 * lg_age)), "thirties", 
  ifelse(data_Salama$age >= (min_age + (2 * lg_age)) & data_Salama$age < (min_age + (3 * lg_age)), "forties",
    ifelse(data_Salama$age >= (min_age + (3 * lg_age)) & data_Salama$age <= (min_age + (4 * lg_age)), "fifties", "Unclassified")))))
head(data_Salama,5)

```


<strong>Nombre de instancias de cada grupo de edad</strong>

```{r,eval=TRUE,echo=TRUE}
library(plyr)
n_g_e <- ddply(data_Salama, .(age_group), nrow)
n_g_e

```




```{r,eval=TRUE,echo=TRUE}

data_Salama <- data_Salama[order(-data_Salama$avg_training_score),]
max_value = data_Salama$avg_training_score[1]

# Calcular los cuartiles de la dataset
max_rows = as.numeric(as.integer(nrow(data_Salama)))
Q2_r= as.numeric( ( max_rows + 1) / 2 )
Q1_r = as.numeric( (as.integer(Q2_r) + 1) / 2 )
Q3_r = as.numeric(  ( as.integer(max_rows) + (as.integer(Q2_r) + 1) )/ 2 )


# Covertir los cuartiles a integers para poder seleccionarlos en la dataset
Q1_i = as.integer(Q1_r)
Q2_i = as.integer(Q2_r)
Q3_i = as.integer(Q3_r)


# Extraer los valores de puntaje de estas lineas
Q1_v = data_Salama$avg_training_score[Q1_i]
Q2_v = data_Salama$avg_training_score[Q2_i]
Q3_v = data_Salama$avg_training_score[Q3_i]

data_Salama <- data_Salama %>%
mutate(data_Salama, training_score_group = ifelse( is.na(data_Salama$avg_training_score), "Abs",
 ifelse(data_Salama$avg_training_score <= Q3_v, "D", 
  ifelse(data_Salama$avg_training_score <= Q2_v, "C",
    ifelse(data_Salama$avg_training_score <= Q1_v , "B", 
      ifelse(data_Salama$avg_training_score <= max_value, "A", "Puntaje no clasificado"))))))
head(data_Salama,5)

```


<strong>Nombre de instancias de cada grupo de puntaje</strong>

```{r,eval=TRUE,echo=TRUE}
library(plyr)
n_g_p <- ddply(data_Salama, .(training_score_group), nrow)
n_g_p
```


# ANOVA DEPARATAMENTOS


La edad de entrada en la empresa varía según el género?
<ol>
<li>La media y la desviación estandar de la variable age para cada departamento "department" 

#Medios y SD de edad_inicio de los generos
```{r,eval=TRUE,echo=TRUE}
dep_age<- aggregate(age~department, data_Salama, function(x) c(mean = mean(x), sd = sd(x)))
dep_age
```



<li>boxplot de la variable employee_start_age para cada grupo de la variable gender


```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
data_means_dep_age <- aggregate(data_Salama$age,                       # Means edad por department
                        list(data_Salama$department),
                        mean)
data_means_dep_age
```


```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}

boxplot(data_Salama$age ~ data_Salama$department)                          
points(x = 1:nrow(data_means_dep_age),                            
       y = data_means_dep_age$x,
       col = "blue",
       pch = 16)
text(x = 1:nrow(data_means_dep_age),                               
     y = data_means_dep_age$x - 0.15,
     labels = paste(round(data_means_dep_age$x, 1)),
     col = "red")

```



</ol>

******
# ANOVA-1 
******

Realiza un análisis ANOVA para determinar si hay diferencias significativas en los valores medios de la variable edad según los departamentos

Empezamos con la hipotesis:

H0:  No hay diferencias significativas en los valores medios de la variable edad 
según los departamentos.

H1:  Hay diferencias significativas en los valores medios de la variable edad 
según los departamentos.



```{r,eval=TRUE,echo=TRUE}
library(plyr)

#nombre de observaciones total
n_emp_total <- nrow(data_Salama)
n_emp_total

#nombre de empleadores en cada departamento
n_emp_dep <- ddply(data_Salama, .(department), nrow)
n_emp_dep

#nombre de departamentos
n_dep <- nrow(n_emp_dep)
n_dep

```



#Obtenemos el valor crítico de una distribución de Fisher para grados de libertad n_dep - 1 y n_emp_total - n_dep, y para una probabilidad 0.05
```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
qf(0.05, n_dep - 1, n_emp_total - n_dep, lower.tail=F)
```


```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
mi.aov = aov(age~department,data = data_Salama)
summary(mi.aov)
```


<ul>
<li> ¿Cuáles son las conclusiones del análisis? 

la propia función R aov() ya nos dice que la probabilidad para el valor F 178 se sitúa en menos de 2e-14%.
Tenemos un valor F (178) posterior al valor  critico (1.938582), entonces rechazamoas la hipótesis nula. 

<li> ¿Se podía esperar este resultado de acuerdo a los análisis realizados en el apartado anterior?
Si este resultado es de acuerdo a los análisis realizados en el apartado anterior por que hemos tenido dos medios con diferencia 
muy alta como por ejemplo el departamento de Financia tiene la media de 32.1 de edad y el de operacion 36.1 de edad. 

</ul>



# ANOVA GENERO



La edad de entrada en la empresa varía según el género?
<ol>
<li>La media y la desviación estandar de la variable Edad de entrada employee_start_age para cada grupo de la variable gender 

#Medios y SD de edad_inicio de los generos


```{r,eval=TRUE,echo=TRUE}
ag2 <- aggregate(employee_start_age~gender, data_Salama, function(x) c(mean = mean(x), sd = sd(x)))
ag2
```



<li>boxplot de la variable employee_start_age para cada grupo de la variable gender


```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
data_means <- aggregate(data_Salama$employee_start_age,                       # Means por genero
                        list(data_Salama$gender),
                        mean)
data_means
```




```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}

boxplot(data_Salama$employee_start_age ~ data_Salama$gender)                          
points(x = 1:nrow(data_means),                            
       y = data_means$x,
       col = "red",
       pch = 16)
text(x = 1:nrow(data_means),                               
     y = data_means$x - 0.15,
     labels = paste("Mean:", round(data_means$x, 1)),
     col = "red")

```

</ol>

******
# ANOVA-1 
******

Realiza un análisis ANOVA para determinar si hay diferencias significativas en los valores medios de la variable employee_start_age según los grupos de la variable gender 

Empezamos con la hipotesis:

H0:  No hay diferencias significativas en los valores medios de la variable employee_start_age 
según los grupos de la variable gender

H1:  hay diferencias significativas en los valores medios de la variable employee_start_age 
según los grupos de la variable gender


```{r,eval=TRUE,echo=TRUE}
library(plyr)

#nombre de observaciones total
n_obse_total <- nrow(data_Salama)
n_obse_total

#nombre de observaciones para cada genero
n_eee <- ddply(data_Salama, .(gender), nrow)
n_eee

#nombre de grupos
n_grupos <- nrow(n_eee)
n_grupos

```



#Obtenemos el valor crítico de una distribución de Fisher para grados de libertad n_grupos - 1 y n_obse_total - n_grupos, y para una probabilidad 0.05
```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
qf(0.05, n_grupos - 1, n_obse_total - n_grupos, lower.tail=F)
```


```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
mi.aov = aov(employee_start_age~gender,data = data_Salama)
summary(mi.aov)
```




<ul>
<li> ¿Cuáles son las conclusiones del análisis? 

la propia función R aov() ya nos dice que la probabilidad para el valor F 2.701 se sitúa en 10%.
Tenemos un valor F (2.701) inferior al valor  critico (3.841628), entonces aceptaremos la hipótesis nula. 

<li> ¿Se podía esperar este resultado de acuerdo a los análisis realizados en el apartado anterior?
Si este resultado es de acuerdo a los análisis realizados en el apartado anterior por que hemos tenido dos medios con diferencia 
muy baja ente 29.001226 y 28.911783 

</ul>

******
# ANOVA-2
******

Ahora hemos realizado un ANOVA de la variable Edad según los grupos generados por la variable training_score_group Se muestra la salida 
del ANOVA (ver fichero HTML).


<ul>
<li> ¿Cuáles son las conclusiones del análisis? 

Tenemos:
Nombre de grupos de puntaje es : 3 + 1 = 4.
Nombre de observaciones es 52244(grado de libertad intra grupos) + 3 + 1 = 52248. 

Varianza entre grupos es: 26174    
Varianza intra grupos: 3033465      

F-value es :150.3 
El p-value del F-statistic: <2e-16


El valor critico:
```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
qf(0.05, 3, 52248, lower.tail=F)
```

Como la F-value 150.3 es muy superior al valor critico que es 2.605079, entonces hay diferencias significativas en los valores medios de la variable age según los grupos de la variable training_score_group.

<li> Sólo con este análisis, ¿podríamos afirmar que hay diferencias significativas en la media de la variable Edad para los grupos de score 1 y 4?
No es bastante suficiente para saber esta variedad ente los medios en nivel de que grupos precisamente, entonces con este analisis sola no podemos saber.
</ul>

******
# Componentes principales (2)
******
<ol>
<li><b>Preparacion de datos</b></li>
Análisis de componentes principales ( técnica de reducción de la dimensión), 
vamos a crear un subconjunto de nuestra base de datos con las variables numéricas, y analizar sus correlaciones


Matriz de correlaciones de estas variables

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
ep_PC=data_Salama[,c("no_of_trainings", "age", "previous_year_rating", "length_of_service", "avg_training_score")]
epc=cor(na.omit(ep_PC))
epc
```

Para Interpretar los resultados, en primero si hay valor de correlacion pisitivo eso significa que los dos variables aumentan y bajan en paralelo.

<ul>
<li> Una correlacion de 4.6% entre los dos variables no_of_trainings y avg_training_score.
<li> Una correlacion de 62% entre los dos variables age y length_of_service, ademas de una correlacion baja de 0.57% entre los variables age y previous_year_rating. 
<li> Una correlacion de 7,5% entre los dos variables previous_year_rating y avg_training_score, ademas una correlacion baja de 0.12% entre la variable previous_year_rating y la variable length_of_service.
<li>  La variable numerica employee_start_age no esta incluida porque es resultado de una substitucion de dos variables numericos que existen en la Matrix que son age y length_of_service, para evitar la redundancia.
</ul>



******
# PCA (3)
******
Realizar la técnica PCA con las variables de la Matrix

```{r,eval=TRUE,echo=FALSE,warning=FALSE, message=FALSE}
pca <- princomp(epc)
pca

```

Contribucion de cada variable a cada componente:

```{r,eval=TRUE,echo=FALSE,warning=FALSE, message=FALSE}
print(cumsum(pca$sdev^2)/sum(pca$sdev^2))

```


El componente 1 contiene el 52% de la variabilidad,
el componente 1 más el componente 2 acumulan el 78% de la variabilidad,
el componente 1 más el componente 2 más el componente 3 acumulan el 96% de la variabilidad, y así succesivamente.

De este modo vemos cómo solo con los tres primeros componentes podemos explicar el 96,77% de la variabilidad de la dataset, 
de manera que el estudio de la proyección del juego de datos inicial sobre estos tres componentes será suficiente para entender aplicar una predicion rezonables. 








* Aquí empieza la parte de Johnsiel
* Aquí empieza la parte de Jose Espaillat

